{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach1 -> Audio Processing -> XGboost and MLP Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset,Dataset\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2Model, BertTokenizer, BertModel, AutoModel, AutoTokenizer, AutoFeatureExtractor\n",
    "from xgboost import XGBRegressor\n",
    "from scipy.stats import uniform, randint\n",
    "import librosa\n",
    "import whisper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MODEL_NAME = \"facebook/wav2vec2-base-960h\"\n",
    "SAMPLE_RATE = 16000\n",
    "TRAIN_AUDIO_DIR = \"dataset_shl/dataset/audios_train\"\n",
    "TEST_AUDIO_DIR =  \"dataset_shl/dataset/audios_test\"\n",
    "TRAIN_CSV_PATH =  \"dataset_shl/dataset/train.csv\"\n",
    "TEST_CSV_PATH =   \"dataset_shl/dataset/test.csv\"\n",
    "df_train = pd.read_csv(TRAIN_CSV_PATH)\n",
    "df_test  = pd.read_csv(TEST_CSV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "processor = Wav2Vec2Processor.from_pretrained(MODEL_NAME)\n",
    "wav2vec_model = Wav2Vec2Model.from_pretrained(MODEL_NAME).to(DEVICE).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(audio_path):\n",
    "    waveform, sr = librosa.load(audio_path , sr = SAMPLE_RATE)\n",
    "    waveform = torch.tensor(waveform).unsqueeze(0)  # shape: [1, num_samples]\n",
    "\n",
    "    input_values = processor(\n",
    "        waveform.squeeze(), \n",
    "        sampling_rate=SAMPLE_RATE, \n",
    "        return_tensors=\"pt\"\n",
    "    ).input_values.to(DEVICE)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = wav2vec_model(input_values)\n",
    "        hidden_states = outputs.last_hidden_state\n",
    "\n",
    "    pooled = hidden_states.mean(dim=1).squeeze().cpu().numpy()\n",
    "    return pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Training dataset features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 444/444 [17:09<00:00,  2.32s/it]\n"
     ]
    }
   ],
   "source": [
    "# Extracting Training Dataset Features \n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "print(\"Extracting Training dataset features...\")\n",
    "for i, row in tqdm(df_train.iterrows(), total=len(df_train)):\n",
    "    file_path = f\"{TRAIN_AUDIO_DIR}/{row['filename']}\"\n",
    "    try:\n",
    "        feat = extract_features(file_path)\n",
    "        features.append(feat)\n",
    "        labels.append(row[\"label\"])\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "X = np.stack(features)\n",
    "y = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T12:06:43.159391Z",
     "iopub.status.busy": "2025-04-05T12:06:43.159091Z",
     "iopub.status.idle": "2025-04-05T12:07:46.492125Z",
     "shell.execute_reply": "2025-04-05T12:07:46.491383Z",
     "shell.execute_reply.started": "2025-04-05T12:06:43.159365Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting TEST dataset features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 195/195 [01:03<00:00,  3.08it/s]\n"
     ]
    }
   ],
   "source": [
    "# Extracting Test Dataset Features \n",
    "\n",
    "features = []\n",
    "print(\"Extracting TEST dataset features...\")\n",
    "for i, row in tqdm(df_test.iterrows(), total=len(df_test)):\n",
    "    file_path = os.path.join(TEST_AUDIO_DIR, row[\"filename\"])\n",
    "    try:\n",
    "        feat = extract_features(file_path)\n",
    "        features.append(feat)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        \n",
    "X_test = np.stack(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T12:07:46.493378Z",
     "iopub.status.busy": "2025-04-05T12:07:46.493089Z",
     "iopub.status.idle": "2025-04-05T12:07:46.498157Z",
     "shell.execute_reply": "2025-04-05T12:07:46.497384Z",
     "shell.execute_reply.started": "2025-04-05T12:07:46.493353Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(195, 768)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBOOST regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "xgb = XGBRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "# Define hyperparameter space\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 500),\n",
    "    'learning_rate': uniform(0.01, 0.3),\n",
    "    'max_depth': randint(3, 10),\n",
    "    'subsample': uniform(0.6, 0.4),\n",
    "    'colsample_bytree': uniform(0.6, 0.4),\n",
    "    'gamma': uniform(0, 5),\n",
    "    'reg_alpha': uniform(0, 1),\n",
    "    'reg_lambda': uniform(0, 1),\n",
    "}\n",
    "\n",
    "# Perform Randomized Search with 5-fold CV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,\n",
    "    scoring='neg_mean_squared_error',  # or use 'r2' for R2 score\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Fit the model\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model after tuning\n",
    "best_model = random_search.best_estimator_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'colsample_bytree': np.float64(0.8976170571996461), 'gamma': np.float64(1.254302636733306), 'learning_rate': np.float64(0.06530010229941101), 'max_depth': 8, 'n_estimators': 378, 'reg_alpha': np.float64(0.42831447494010777), 'reg_lambda': np.float64(0.6884999007653664), 'subsample': np.float64(0.6232774382033774)}\n",
      "Validation RMSE: 0.9045103837662085\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on validation set\n",
    "val_preds = best_model.predict(X_val)\n",
    "val_score = root_mean_squared_error(y_val, val_preds)  # RMSE\n",
    "\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "print(\"Validation RMSE:\", val_score)\n",
    "torch.save(model.state_dict(), f\"best_model_xgboost.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T06:16:48.824753Z",
     "iopub.status.busy": "2025-04-05T06:16:48.824429Z",
     "iopub.status.idle": "2025-04-05T06:16:48.839133Z",
     "shell.execute_reply": "2025-04-05T06:16:48.838364Z",
     "shell.execute_reply.started": "2025-04-05T06:16:48.824726Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>audio_706.wav</td>\n",
       "      <td>2.264599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>audio_800.wav</td>\n",
       "      <td>3.339555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>audio_68.wav</td>\n",
       "      <td>3.814336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>audio_1267.wav</td>\n",
       "      <td>3.140778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>audio_683.wav</td>\n",
       "      <td>2.583885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         filename     label\n",
       "0   audio_706.wav  2.264599\n",
       "1   audio_800.wav  3.339555\n",
       "2    audio_68.wav  3.814336\n",
       "3  audio_1267.wav  3.140778\n",
       "4   audio_683.wav  2.583885"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds = model_1.predict(X_test)\n",
    "df_test_preds = pd.DataFrame()\n",
    "df_test_preds[\"filename\"] = df_test['filename']\n",
    "df_test_preds['label'] = test_preds\n",
    "\n",
    "df_test_preds.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T06:16:51.817867Z",
     "iopub.status.busy": "2025-04-05T06:16:51.817579Z",
     "iopub.status.idle": "2025-04-05T06:16:51.823551Z",
     "shell.execute_reply": "2025-04-05T06:16:51.822637Z",
     "shell.execute_reply.started": "2025-04-05T06:16:51.817842Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test_preds.to_csv(\"sub.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEEP MLP REGRESSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPRegressor(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MLPRegressor, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(64, 1)  # Final regression output\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_model(model, X_train, y_train, X_val, y_val, epochs=500, batch_size=32, lr=1e-4, patience=5):\n",
    "    # Prepare data\n",
    "    train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32),\n",
    "                                  torch.tensor(y_train, dtype=torch.float32).unsqueeze(1))\n",
    "    val_dataset = TensorDataset(torch.tensor(X_val, dtype=torch.float32),\n",
    "                                torch.tensor(y_val, dtype=torch.float32).unsqueeze(1))\n",
    "\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset,\n",
    "                            batch_size=batch_size)\n",
    "\n",
    "    # Loss & optimizer\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        preds = []\n",
    "        actuals = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                val_losses.append(loss.item())\n",
    "\n",
    "                preds.extend(outputs.squeeze().cpu().numpy())\n",
    "                actuals.extend(y_batch.squeeze().cpu().numpy())\n",
    "\n",
    "        avg_train_loss = sum(train_losses) / len(train_losses)\n",
    "        avg_val_loss = sum(val_losses) / len(val_losses)\n",
    "        rmse = np.sqrt(mean_squared_error(actuals, preds))\n",
    "        if((epoch+1)%10 == 0):\n",
    "            print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Val RMSE: {rmse:.4f}\")\n",
    "\n",
    "        # Early stopping\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), \"best_model_Bert_plus_MLP.pt\")  # Save best model\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "\n",
    "    # Load best model before returning\n",
    "    model.load_state_dict(torch.load(\"best_model_Bert_plus_MLP.pt\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/500 | Train Loss: 5.6875 | Val Loss: 7.2051 | Val RMSE: 2.6986\n",
      "Epoch 20/500 | Train Loss: 1.2488 | Val Loss: 2.1421 | Val RMSE: 1.4854\n",
      "Epoch 30/500 | Train Loss: 0.7752 | Val Loss: 1.3711 | Val RMSE: 1.1871\n",
      "Epoch 40/500 | Train Loss: 0.7362 | Val Loss: 1.2589 | Val RMSE: 1.1335\n",
      "Epoch 50/500 | Train Loss: 0.6708 | Val Loss: 1.3590 | Val RMSE: 1.1740\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syedd\\AppData\\Local\\Temp\\ipykernel_75124\\2495675284.py:70: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_model_Bert_plus_MLP.pt\"))\n"
     ]
    }
   ],
   "source": [
    "model = MLPRegressor(input_dim=X_train.shape[1]).to(DEVICE)\n",
    "trained_model = train_model(model, X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, X_test, batch_size=32):\n",
    "    model.eval()\n",
    "    test_dataset = torch.tensor(X_test, dtype=torch.float32)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader:\n",
    "            X_batch = X_batch.to(DEVICE)\n",
    "            outputs = model(X_batch)\n",
    "            predictions.extend(outputs.squeeze().cpu().numpy())\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T06:35:08.423196Z",
     "iopub.status.busy": "2025-04-05T06:35:08.422909Z",
     "iopub.status.idle": "2025-04-05T06:35:08.437417Z",
     "shell.execute_reply": "2025-04-05T06:35:08.436525Z",
     "shell.execute_reply.started": "2025-04-05T06:35:08.423174Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict on X_test\n",
    "test_preds = predict(trained_model, X_test)\n",
    "\n",
    "# Create submission file (example)\n",
    "df_test_preds = pd.DataFrame({\n",
    "    \"filename\": df_test[\"filename\"],  # Make sure df_test has this column\n",
    "    \"label\": test_preds\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "df_test_preds.to_csv(\"submission2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 2 -> Consider Audio Waveform as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syedd\\miniconda3\\envs\\hmenv3\\Lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "model_whisper = whisper.load_model(\"base\")\n",
    "model_whisper = model_whisper.to(DEVICE)\n",
    "def transcribe_audio(file_path):\n",
    "    try:\n",
    "        result = model_whisper.to(DEVICE).transcribe(file_path)\n",
    "        return result[\"text\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Error transcribing {file_path}: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = f'{TRAIN_AUDIO_DIR}/{df_train.iloc[20][\"filename\"]}'\n",
    "transcript = transcribe_audio(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### # Pre_Extract the transcripts and save them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts_train = []\n",
    "print(\"Extracting Train dataset Transcripts...\")\n",
    "for i, row in tqdm(df_train.iterrows(), total=len(df_train)):\n",
    "    file_path = f'{TRAIN_AUDIO_DIR}/{row[\"filename\"]}'\n",
    "    try:\n",
    "        transcript = transcribe_audio(file_path, DEVICE)\n",
    "        transcripts_train.append(transcript)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(TEST_CSV_PATH)\n",
    "transcripts_test = []\n",
    "print(\"Extracting Train dataset Transcripts...\")\n",
    "for i, row in tqdm(df_test.iterrows(), total=len(df_test)):\n",
    "    file_path = os.path.join(TEST_AUDIO_DIR, row[\"filename\"])\n",
    "    try:\n",
    "        transcript = transcribe_audio(file_path,DEVICE)\n",
    "        transcripts.append(transcript)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_transcript = pd.DataFrame() \n",
    "df_train_transcript['text'] = transcripts_train\n",
    "df_train_transcript['label'] = df_train['label']\n",
    "df_train_transcript['filename'] = df_train['filename']\n",
    "df_train_transcript.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_transcript = pd.DataFrame() \n",
    "df_test_transcript['text'] = transcripts\n",
    "df_test_transcript['filename'] = df_test['filename']\n",
    "df_test_transcript.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_transcript.to_csv(\"train_transcript.csv\",index = False)\n",
    "df_test_transcript.to_csv(\"test_transcript.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transcripted Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranscriptDataset(Dataset):\n",
    "    def __init__(self , df , tokenizer,max_len = 128,training = True):\n",
    "        self.texts = df[\"text\"].tolist()\n",
    "        self.texts = [str(t) if pd.notna(t) else \"\" for t in self.texts]  # Ensures string input\n",
    "\n",
    "        if training:\n",
    "            self.labels = df[\"label\"].tolist()\n",
    "        self.tokenizer= tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.training = training\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        encodings = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        input_ids = encodings[\"input_ids\"].squeeze(0)\n",
    "        attention_mask = encodings[\"attention_mask\"].squeeze(0)\n",
    "        if (self.training == True):\n",
    "            label = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "\n",
    "            return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"label\": label\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask\n",
    "            }\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTRegression(nn.Module):\n",
    "    def __init__(self, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(self.bert.config.hidden_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled = outputs.pooler_output  # [CLS] token representation\n",
    "        raw_output = self.regressor(pooled).squeeze(1)\n",
    "        scaled_output = 5 * torch.sigmoid(raw_output)  # Constrain to [0, 5]\n",
    "        return scaled_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in (loader):\n",
    "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "        labels = batch[\"label\"].to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def eval_epoch(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    preds, actuals = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in (loader):\n",
    "            input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "            attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "            labels = batch[\"label\"].to(DEVICE)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            preds.extend(outputs.cpu().numpy())\n",
    "            actuals.extend(labels.cpu().numpy())\n",
    "    return total_loss / len(loader), preds, actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model, Loss, Optimizer\n",
    "model = BERTRegression(dropout = 0.4).to(DEVICE)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "BATCH_SIZE = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df_train_transcript = pd.read_csv(\"dataset_shl/dataset/train_transcript.csv\")\n",
    "train_df, val_df = train_test_split(df_train_transcript, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Dataset & DataLoader\n",
    "train_dataset = TranscriptDataset(train_df, tokenizer)\n",
    "val_dataset = TranscriptDataset(val_df, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████                                                                         | 10/100 [04:39<41:49, 27.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.2371 | Val Loss: 0.6382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▏                                                                | 20/100 [09:17<37:02, 27.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Loss: 0.1315 | Val Loss: 0.7304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▎                                                        | 30/100 [13:54<32:23, 27.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | Train Loss: 0.0588 | Val Loss: 0.7193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████████████████████▍                                                | 40/100 [18:32<27:44, 27.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 | Train Loss: 0.0515 | Val Loss: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|██████████████████████████████████████                                           | 47/100 [21:50<24:38, 27.89s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[196], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m best_val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(epochs)):\n\u001b[1;32m----> 5\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     val_loss, preds, labels \u001b[38;5;241m=\u001b[39m eval_epoch(model, val_loader, criterion)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (val_loss \u001b[38;5;241m<\u001b[39m best_val_loss):\n",
      "Cell \u001b[1;32mIn[193], line 13\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(model, loader, optimizer, criterion)\u001b[0m\n\u001b[0;32m     11\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     12\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 13\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(loader)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\hmenv3\\Lib\\site-packages\\torch\\optim\\optimizer.py:487\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    482\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    483\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    484\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    485\u001b[0m             )\n\u001b[1;32m--> 487\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    490\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\hmenv3\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\hmenv3\\Lib\\site-packages\\transformers\\optimization.py:695\u001b[0m, in \u001b[0;36mAdamW.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    691\u001b[0m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    693\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m    694\u001b[0m \u001b[38;5;66;03m# In-place operations to update the averages at the same time\u001b[39;00m\n\u001b[1;32m--> 695\u001b[0m \u001b[43mexp_avg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39madd_(grad, alpha\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m beta1))\n\u001b[0;32m    696\u001b[0m exp_avg_sq\u001b[38;5;241m.\u001b[39mmul_(beta2)\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[0;32m    697\u001b[0m denom \u001b[38;5;241m=\u001b[39m exp_avg_sq\u001b[38;5;241m.\u001b[39msqrt()\u001b[38;5;241m.\u001b[39madd_(group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meps\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "epochs = 100\n",
    "best_val_loss = float('inf')\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, criterion)\n",
    "    val_loss, preds, labels = eval_epoch(model, val_loader, criterion)\n",
    "    if (val_loss < best_val_loss):\n",
    "        torch.save(model.state_dict(), \"bert_MLP_regressor.pt\")\n",
    "        best_val_loss = val_loss\n",
    "    if((epoch+1)%10==0):\n",
    "        print(f\"Epoch {epoch+1} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_transcript = pd.read_csv(\"dataset_shl/dataset/test_transcript.csv\")\n",
    "test_dataset = TranscriptDataset(df_test_transcript, tokenizer, training = False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_loader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Predicting\"):\n",
    "            input_ids = batch['input_ids'].to(DEVICE)\n",
    "            attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syedd\\AppData\\Local\\Temp\\ipykernel_75124\\4055783567.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"bert_MLP_regressor.pt\"))\n",
      "Predicting: 100%|██████████████████████████████████████████████████████████████████████| 13/13 [00:11<00:00,  1.15it/s]\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"bert_MLP_regressor.pt\"))\n",
    "predictions = predict(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>audio_706.wav</td>\n",
       "      <td>4.486119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>audio_800.wav</td>\n",
       "      <td>2.264364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>audio_68.wav</td>\n",
       "      <td>3.921659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>audio_1267.wav</td>\n",
       "      <td>2.468159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>audio_683.wav</td>\n",
       "      <td>2.256742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         filename     label\n",
       "0   audio_706.wav  4.486119\n",
       "1   audio_800.wav  2.264364\n",
       "2    audio_68.wav  3.921659\n",
       "3  audio_1267.wav  2.468159\n",
       "4   audio_683.wav  2.256742"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df = pd.DataFrame()\n",
    "sub_df['filename'] = df_test['filename']\n",
    "sub_df['label'] = predictions\n",
    "sub_df.to_csv(\"sub3.csv\",index = False)\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach -> Weighted merge of different approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_merge(df1, df2, alpha=0.5):\n",
    "    # Ensure filenames match and merge\n",
    "    merged = pd.merge(df1, df2, on='filename', how='inner', suffixes=('_1', '_2'))\n",
    "\n",
    "    # Compute weighted sum of scores\n",
    "    merged['label'] = alpha * merged['label_1'] + (1-alpha) * merged['label_2']\n",
    "\n",
    "    # Return only required columns\n",
    "    return merged[['filename', 'label']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T17:15:11.963825Z",
     "iopub.status.busy": "2025-04-05T17:15:11.963375Z",
     "iopub.status.idle": "2025-04-05T17:15:11.979704Z",
     "shell.execute_reply": "2025-04-05T17:15:11.978742Z",
     "shell.execute_reply.started": "2025-04-05T17:15:11.963800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>audio_706.wav</td>\n",
       "      <td>3.112394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>audio_800.wav</td>\n",
       "      <td>2.808166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>audio_68.wav</td>\n",
       "      <td>3.912927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>audio_1267.wav</td>\n",
       "      <td>2.910975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>audio_683.wav</td>\n",
       "      <td>2.511891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         filename     label\n",
       "0   audio_706.wav  3.112394\n",
       "1   audio_800.wav  2.808166\n",
       "2    audio_68.wav  3.912927\n",
       "3  audio_1267.wav  2.910975\n",
       "4   audio_683.wav  2.511891"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df_prev = pd.read_csv(\"submission2.csv\")\n",
    "sub_df4 = weighted_merge(sub_df,sub_df_prev)\n",
    "sub_df4.to_csv(\"sub4.csv\",index = False)\n",
    "sub_df4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach ->  Synthetic data merged traininig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T16:44:04.872675Z",
     "iopub.status.busy": "2025-04-05T16:44:04.872359Z",
     "iopub.status.idle": "2025-04-05T16:44:04.905487Z",
     "shell.execute_reply": "2025-04-05T16:44:04.904651Z",
     "shell.execute_reply.started": "2025-04-05T16:44:04.872654Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My family go to beach last weekend. My family ...</td>\n",
       "      <td>3.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>He is very like play game. I go market buy fru...</td>\n",
       "      <td>1.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>He likes to playing football in evening.</td>\n",
       "      <td>3.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>He is very like play game.</td>\n",
       "      <td>1.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I go market buy fruit. No good shop. He is ver...</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  My family go to beach last weekend. My family ...   3.37\n",
       "1  He is very like play game. I go market buy fru...   1.71\n",
       "2           He likes to playing football in evening.   3.56\n",
       "3                         He is very like play game.   1.46\n",
       "4  I go market buy fruit. No good shop. He is ver...   1.20"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_transcript = pd.read_csv(\"/kaggle/input/test-and-train-kaggle-dataset-transcripts/train_transcript.csv\")\n",
    "synthetic_data_df = pd.read_csv(\"dataset_shl/dataset/synthetic_transcript_dataset_2.csv\")\n",
    "synthetic_data_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T16:44:12.226705Z",
     "iopub.status.busy": "2025-04-05T16:44:12.226407Z",
     "iopub.status.idle": "2025-04-05T16:44:12.237177Z",
     "shell.execute_reply": "2025-04-05T16:44:12.236284Z",
     "shell.execute_reply.started": "2025-04-05T16:44:12.226685Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1444\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My family go to beach last weekend. My family ...</td>\n",
       "      <td>3.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>He is very like play game. I go market buy fru...</td>\n",
       "      <td>1.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>He likes to playing football in evening.</td>\n",
       "      <td>3.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>He is very like play game.</td>\n",
       "      <td>1.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I go market buy fruit. No good shop. He is ver...</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  My family go to beach last weekend. My family ...   3.37\n",
       "1  He is very like play game. I go market buy fru...   1.71\n",
       "2           He likes to playing football in evening.   3.56\n",
       "3                         He is very like play game.   1.46\n",
       "4  I go market buy fruit. No good shop. He is ver...   1.20"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated_df = pd.concat([synthetic_data_df, df_train_transcript], ignore_index=True)\n",
    "print(len(concatenated_df))\n",
    "concatenated_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T16:44:57.966535Z",
     "iopub.status.busy": "2025-04-05T16:44:57.966148Z",
     "iopub.status.idle": "2025-04-05T16:44:58.195682Z",
     "shell.execute_reply": "2025-04-05T16:44:58.194887Z",
     "shell.execute_reply.started": "2025-04-05T16:44:57.966502Z"
    }
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load data\n",
    "concatenated_df = concatenated_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "train_df, val_df = train_test_split(concatenated_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Dataset & DataLoader\n",
    "train_dataset = TranscriptDataset(train_df, tokenizer)\n",
    "val_dataset = TranscriptDataset(val_df, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size = BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T16:50:18.202453Z",
     "iopub.status.busy": "2025-04-05T16:50:18.202057Z",
     "iopub.status.idle": "2025-04-05T16:50:18.786271Z",
     "shell.execute_reply": "2025-04-05T16:50:18.785599Z",
     "shell.execute_reply.started": "2025-04-05T16:50:18.202424Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model, Loss, Optimizer\n",
    "model = BERTRegression(dropout = 0.4).to(DEVICE)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T16:59:28.673288Z",
     "iopub.status.busy": "2025-04-05T16:59:28.672792Z",
     "iopub.status.idle": "2025-04-05T17:07:27.782606Z",
     "shell.execute_reply": "2025-04-05T17:07:27.781753Z",
     "shell.execute_reply.started": "2025-04-05T16:59:28.673249Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [02:42<24:23, 32.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Train Loss: 0.1090 | Val Loss: 0.2603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [05:20<21:13, 31.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.0953 | Val Loss: 0.2908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [07:59<20:31, 34.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "epochs = 50\n",
    "patience_counter = 0\n",
    "best_val_loss = 1000000\n",
    "patience = 10\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, criterion)\n",
    "    avg_val_loss, preds, labels = eval_epoch(model, val_loader, criterion)\n",
    "    if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), \"best_model_with_synthetic_transcript.pt\")  # Save best model\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "\n",
    "    if((epoch+1)%5==0):\n",
    "        print(f\"Epoch {epoch+1} | Train Loss: {train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T17:09:59.781541Z",
     "iopub.status.busy": "2025-04-05T17:09:59.781201Z",
     "iopub.status.idle": "2025-04-05T17:10:02.081928Z",
     "shell.execute_reply": "2025-04-05T17:10:02.080938Z",
     "shell.execute_reply.started": "2025-04-05T17:09:59.781515Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-50-2281680ae404>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_model_transcript.pt\"))\n",
      "Predicting: 100%|██████████| 13/13 [00:01<00:00,  6.68it/s]\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"best_model_with_synthetic_transcript.pt\"))\n",
    "predictions = predict(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T17:10:41.275156Z",
     "iopub.status.busy": "2025-04-05T17:10:41.274812Z",
     "iopub.status.idle": "2025-04-05T17:10:41.293803Z",
     "shell.execute_reply": "2025-04-05T17:10:41.292862Z",
     "shell.execute_reply.started": "2025-04-05T17:10:41.275131Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>audio_706.wav</td>\n",
       "      <td>3.960189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>audio_800.wav</td>\n",
       "      <td>2.276778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>audio_68.wav</td>\n",
       "      <td>4.011518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>audio_1267.wav</td>\n",
       "      <td>2.681172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>audio_683.wav</td>\n",
       "      <td>2.439897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         filename     label\n",
       "0   audio_706.wav  3.960189\n",
       "1   audio_800.wav  2.276778\n",
       "2    audio_68.wav  4.011518\n",
       "3  audio_1267.wav  2.681172\n",
       "4   audio_683.wav  2.439897"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df = pd.DataFrame()\n",
    "sub_df['filename'] = df_test['filename']\n",
    "sub_df['label'] = predictions\n",
    "sub_df.to_csv(\"sub6.csv\",index = False)\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weighted Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T17:13:43.438237Z",
     "iopub.status.busy": "2025-04-05T17:13:43.437873Z",
     "iopub.status.idle": "2025-04-05T17:13:43.475649Z",
     "shell.execute_reply": "2025-04-05T17:13:43.474833Z",
     "shell.execute_reply.started": "2025-04-05T17:13:43.438209Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>audio_706.wav</td>\n",
       "      <td>3.112394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>audio_800.wav</td>\n",
       "      <td>2.808166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>audio_68.wav</td>\n",
       "      <td>3.912927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>audio_1267.wav</td>\n",
       "      <td>2.910975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>audio_683.wav</td>\n",
       "      <td>2.511891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         filename     label\n",
       "0   audio_706.wav  3.112394\n",
       "1   audio_800.wav  2.808166\n",
       "2    audio_68.wav  3.912927\n",
       "3  audio_1267.wav  2.910975\n",
       "4   audio_683.wav  2.511891"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df_prev = pd.read_csv(\"sub.csv\")\n",
    "sub_df7 = weighted_merge(sub_df,sub_df_prev)\n",
    "sub_df7.to_csv(\"sub7.csv\",index = False)\n",
    "sub_df7.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach -> Multimodal archtecture i.e. Use both audio and transcript features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>audio_1261.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The playground looks like very clear and neat...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>audio_942.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011 2011 2007 nd to have a about the electro...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>audio_1110.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My favorite place is in Andhra Pradesh. It is...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>audio_1024.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My favorite place is UTI and PRAKAN. My exper...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>audio_538.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label        filename\n",
       "0   1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% ...    1.0  audio_1261.wav\n",
       "1   The playground looks like very clear and neat...    1.5   audio_942.wav\n",
       "2   2011 2011 2007 nd to have a about the electro...    1.5  audio_1110.wav\n",
       "3   My favorite place is in Andhra Pradesh. It is...    1.5  audio_1024.wav\n",
       "4   My favorite place is UTI and PRAKAN. My exper...    2.0   audio_538.wav"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_kaggle = pd.read_csv(\"dataset_shl/dataset/train.csv\")\n",
    "train_transcript_data = pd.read_csv(\"dataset_shl/dataset/train_transcript.csv\")\n",
    "train_transcript_data['filename'] = df_train_kaggle['filename']\n",
    "train_transcript_data.head()\n",
    "# len(df_train_kaggle),len(train_transcript_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_model= \"facebook/wav2vec2-base-960h\"\n",
    "text_model =  \"bert-base-uncased\"\n",
    "learning_rate = 2e-5\n",
    "batch_size = 1\n",
    "epochs = 50\n",
    "audio_max_len = 16000*60\n",
    "text_max_len = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrammarDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, feature_extractor, task, audio_max_len=16000*60):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data (DataFrame): Contains 'filename', 'text', and optionally 'label'.\n",
    "            tokenizer: Hugging Face tokenizer for text.\n",
    "            feature_extractor: Hugging Face feature extractor for audio.\n",
    "            task (str): 'train' or other (inference/eval).\n",
    "            audio_max_len (int): Max audio length in samples (default is 60s at 16kHz).\n",
    "        \"\"\"\n",
    "        \n",
    "        self.data = data #Dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.task = task\n",
    "        self.audio_max_len = audio_max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data.iloc[idx]\n",
    "        file_path = f'dataset_shl/dataset/audios_{self.task}/{item[\"filename\"]}'\n",
    "        \n",
    "        # Load audio\n",
    "        audio, sr = librosa.load(file_path, sr=16000)\n",
    "\n",
    "        # Pad or truncate audio\n",
    "        audio_tensor = torch.tensor(audio)\n",
    "        if len(audio_tensor) < self.audio_max_len:\n",
    "            pad_len = self.audio_max_len - len(audio_tensor)\n",
    "            audio_tensor = F.pad(audio_tensor, (0, pad_len))\n",
    "        else:\n",
    "            audio_tensor = audio_tensor[:self.audio_max_len]\n",
    "\n",
    "        # Extract audio features\n",
    "        audio_features = self.feature_extractor(\n",
    "            audio_tensor.numpy(),\n",
    "            sampling_rate=sr,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        # Extract text features\n",
    "        text = item.get('text', '')\n",
    "        if not isinstance(text, str):\n",
    "            text = ''\n",
    "        text_features = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=128,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        # Package features\n",
    "        sample = {\n",
    "            'audio_input': audio_features.input_values.squeeze(0),\n",
    "            'text_input_ids': text_features.input_ids.squeeze(0),\n",
    "            'text_attention_mask': text_features.attention_mask.squeeze(0)\n",
    "        }\n",
    "\n",
    "        # Add label if training\n",
    "        if self.task == 'train':\n",
    "            sample['label'] = torch.tensor(item['label'], dtype=torch.float)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "waveform, sample_rate = librosa.load(\"dataset_shl/dataset/audios_train/audio_1128.wav\" , sr = 16000)\n",
    "plt.figure(figsize=(12, 4))\n",
    "librosa.display.waveshow(waveform, sr=16000)\n",
    "plt.title(\"Waveform of audio_1008.wav\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalGrammarScorer(nn.Module):\n",
    "    def __init__(self, audio_model_name, text_model_name):\n",
    "        super().__init__()\n",
    "        self.audio_encoder = AutoModel.from_pretrained(audio_model_name)\n",
    "        self.text_encoder = AutoModel.from_pretrained(text_model_name)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.audio_encoder.config.hidden_size + self.text_encoder.config.hidden_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, audio_input, text_input_ids, text_attention_mask):\n",
    "        audio_embed = self.audio_encoder(audio_input).last_hidden_state[:, 0, :]  # CLS Token\n",
    "        text_embed = self.text_encoder(input_ids=text_input_ids, attention_mask=text_attention_mask).last_hidden_state[:, 0, :]\n",
    "        \n",
    "        combined = torch.cat([audio_embed, text_embed], dim=1)\n",
    "        output = self.fc(combined)\n",
    "        \n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9913"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(text_model)\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(audio_model)\n",
    "\n",
    "# Load your train_data / val_data\n",
    "train_df, val_df = train_test_split(train_transcript_data, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = GrammarDataset(train_df, tokenizer, feature_extractor,task = 'train')\n",
    "val_dataset = GrammarDataset(val_df, tokenizer, feature_extractor , task = 'train')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = MultimodalGrammarScorer(audio_model, text_model).cuda()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/355 [00:00<?, ?it/s]C:\\Users\\syedd\\miniconda3\\envs\\hmenv3\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:608: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 355/355 [01:35<00:00,  3.70it/s]\n",
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 89/89 [00:07<00:00, 11.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Loss : 0.2085830271244049 : Val Loss : 2.4994354248046875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 355/355 [01:35<00:00,  3.71it/s]\n",
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 89/89 [00:07<00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss : 3.568352222442627 : Val Loss : 0.35052555799484253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 355/355 [01:35<00:00,  3.73it/s]\n",
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 89/89 [00:07<00:00, 12.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss : 0.19680015742778778 : Val Loss : 0.1666007936000824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 355/355 [01:36<00:00,  3.68it/s]\n",
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 89/89 [00:07<00:00, 12.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss : 0.011868573725223541 : Val Loss : 0.28118637204170227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 355/355 [01:35<00:00,  3.72it/s]\n",
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 89/89 [00:07<00:00, 12.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss : 0.08695416152477264 : Val Loss : 0.9346666932106018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 355/355 [01:35<00:00,  3.70it/s]\n",
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 89/89 [00:07<00:00, 12.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss : 0.030902065336704254 : Val Loss : 0.4975524842739105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|████████████████████████████████████████████████████████████████████████████▊   | 341/355 [01:32<00:03,  3.70it/s]"
     ]
    }
   ],
   "source": [
    "best_rmse = float('inf')\n",
    "patience = 0\n",
    "patience_limit = 10\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for batch in tqdm(train_loader):\n",
    "        audio_input = batch['audio_input'].cuda()\n",
    "        text_input_ids = batch['text_input_ids'].cuda()\n",
    "        text_attention_mask = batch['text_attention_mask'].cuda()\n",
    "        scores = batch['label'].cuda()\n",
    "\n",
    "        preds = model(audio_input, text_input_ids, text_attention_mask)\n",
    "        train_loss = loss_fn(preds, scores)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc = 'Evaluating'):\n",
    "        \n",
    "            audio_input = batch['audio_input'].cuda()\n",
    "            text_input_ids = batch['text_input_ids'].cuda()\n",
    "            text_attention_mask = batch['text_attention_mask'].cuda()\n",
    "            scores = batch['label'].cuda()\n",
    "    \n",
    "            preds = model(audio_input, text_input_ids, text_attention_mask)\n",
    "            val_loss = loss_fn(preds, scores)\n",
    "\n",
    "    print(f\"Epoch {epoch}: Train Loss : {train_loss.item()} : Val Loss : {val_loss}\")\n",
    "\n",
    "    if val_loss < best_rmse:\n",
    "        patience = 0\n",
    "        best_rmse = val_loss\n",
    "        torch.save(model.state_dict(), f\"best_model_audio_plus_text_bert_whisper.pt\")\n",
    "            # print(f\"Saved Best Model with RMSE: {best_rmse:.4f}\")\n",
    "    else:\n",
    "        patience = patience + 1\n",
    "        if(patience > patience_limit):\n",
    "            print(\"Early Stopping\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = GrammarDataset(test_transcript_data, tokenizer, feature_extractor,task = 'test')\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_loader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Predicting\"):\n",
    "            audio_input = batch['audio_input'].cuda()\n",
    "            text_input_ids = batch['text_input_ids'].cuda()\n",
    "            text_attention_mask = batch['text_attention_mask'].cuda()\n",
    "            # scores = batch['label'].cuda()\n",
    "    \n",
    "            preds = model(audio_input, text_input_ids, text_attention_mask)\n",
    "            predictions.append(preds.cpu().numpy())\n",
    "\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|████████████████████████████████████████████████████████████████████| 195/195 [00:16<00:00, 11.79it/s]\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"best_model_audio_plus_text_bert_whisper.pt\"))\n",
    "predictions = predict(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>audio_706.wav</td>\n",
       "      <td>4.375926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>audio_800.wav</td>\n",
       "      <td>2.199115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>audio_68.wav</td>\n",
       "      <td>3.6435082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>audio_1267.wav</td>\n",
       "      <td>2.326678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>audio_683.wav</td>\n",
       "      <td>2.5672758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         filename      label\n",
       "0   audio_706.wav   4.375926\n",
       "1   audio_800.wav   2.199115\n",
       "2    audio_68.wav  3.6435082\n",
       "3  audio_1267.wav   2.326678\n",
       "4   audio_683.wav  2.5672758"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"dataset_shl/dataset/test.csv\")\n",
    "sub_df = pd.DataFrame()\n",
    "sub_df['filename'] = df_test['filename']\n",
    "sub_df['label'] = predictions\n",
    "sub_df.to_csv(\"sub9.csv\", index = False)\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weighted Merges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"sub.csv\")\n",
    "sub_plus_9 = weighted_merge(sub_df , sub)\n",
    "sub_plus_9.to_csv(\"sub_plus_9.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using WaveLM sota speach model for feature extration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Audio encoder: WavLM -----\n",
    "wavlm_bundle = torchaudio.pipelines.WAVLM_BASE\n",
    "wavlm_model = wavlm_bundle.get_model().eval().to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ----- Text encoder: BERT base -----\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased').eval().to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----- Load and preprocess audio using Librosa -----\n",
    "def load_audio_librosa(filepath, target_sr=16000):\n",
    "    waveform, sr = librosa.load(filepath, sr=target_sr)\n",
    "    waveform_tensor = torch.tensor(waveform).float().to(device)\n",
    "    return waveform_tensor\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_audio_embedding(filepath):\n",
    "    waveform = load_audio_librosa(filepath)\n",
    "    if waveform.dim() == 1:\n",
    "        waveform = waveform.unsqueeze(0)\n",
    "    features = wavlm_model(waveform)  # (1, T', 768)\n",
    "    pooled = features[0].mean(dim=1)  # (1, 768)\n",
    "    return pooled.squeeze(0)  # (768,)\n",
    "\n",
    "# ----- Process transcript with BERT -----\n",
    "@torch.no_grad()\n",
    "def get_text_embedding(transcript):\n",
    "    \n",
    "    if not isinstance(transcript, str):\n",
    "        transcript = \"\"\n",
    "    tokens = bert_tokenizer(transcript, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(device)\n",
    "    outputs = bert_model(**tokens)\n",
    "    cls_embedding = outputs.last_hidden_state[:, 0, :]  # CLS token (1, 768)\n",
    "    return cls_embedding.squeeze(0)  # (768,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model class for concatenating CLS tokens of audio and text embeddings then feeding to MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioTextFusionModel(nn.Module):\n",
    "    def __init__(self, hidden_size=768):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, audio_embed, text_embed):\n",
    "        x = torch.cat([audio_embed, text_embed], dim=-1)  # (B, 1536)\n",
    "        return self.model(x) * 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transcript_data = pd.read_csv(\"dataset_shl/dataset/train_transcript.csv\")\n",
    "idx = 336\n",
    "text_embed = train_transcript_data.iloc[idx]['text']\n",
    "audio_filename = train_transcript_data.iloc[idx]['filename']\n",
    "score = train_transcript_data.iloc[idx]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_transcript = text_embed\n",
    "sample_audio_path = \"dataset_shl/dataset/audios_train/audio_942.wav\"\n",
    "\n",
    "# Get embeddings\n",
    "audio_feat = get_audio_embedding(sample_audio_path)  # (768,)\n",
    "text_feat = get_text_embedding(sample_transcript)    # (768,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([768]), torch.Size([768]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_feat.shape,text_feat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUSTOM DATASET CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioTextDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, task = 'train' ,max_len=128):\n",
    "        \"\"\"\n",
    "        data: Dataframe with columns: 'filename', 'text', 'label'\n",
    "        tokenizer: HuggingFace tokenizer (e.g., BERT)\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.task = task\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        entry = self.data.iloc[idx]\n",
    "        audio_path = f'dataset_shl/dataset/audios_{self.task}/{entry[\"filename\"]}'\n",
    "        transcript = entry['text']\n",
    "        target = 0\n",
    "        if (self.task!= 'test'):\n",
    "            target = torch.tensor(entry['label'], dtype=torch.float)\n",
    "\n",
    "        # Text embedding\n",
    "        text_feat = get_text_embedding(transcript)    # (768,)\n",
    "        \n",
    "        # Audio embedding\n",
    "        audio_feat = get_audio_embedding(audio_path)  # (768,)\n",
    "\n",
    "        return audio_feat, text_feat, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_data = train_transcript_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "train_data, val_data = train_test_split(shuffled_data, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precomute and save audio and text embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precompute_and_save_embeddings(df, task='train', out_dir='cached_embeddings'):\n",
    "    os.makedirs(f\"{out_dir}/{task}/audio\", exist_ok=True)\n",
    "    os.makedirs(f\"{out_dir}/{task}/text\", exist_ok=True)\n",
    "\n",
    "    for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        audio_path = f'dataset_shl/dataset/audios_{task}/{row[\"filename\"]}'\n",
    "        transcript = row['text']\n",
    "\n",
    "        audio_feat = get_audio_embedding(audio_path).cpu()\n",
    "        text_feat = get_text_embedding(transcript).cpu()\n",
    "\n",
    "        torch.save(audio_feat, f\"{out_dir}/{task}/audio/{row['filename']}.pt\")\n",
    "        torch.save(text_feat, f\"{out_dir}/{task}/text/{row['filename']}.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precompute_and_save_embeddings(train_data)\n",
    "# precompute_and_save_embeddings(val_data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrecomputedFusionDataset(Dataset):\n",
    "    def __init__(self, df, embedding_dir='cached_embeddings', task='train'):\n",
    "        self.df = df\n",
    "        self.audio_dir = f\"{embedding_dir}/{task}/audio\"\n",
    "        self.text_dir = f\"{embedding_dir}/{task}/text\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        audio_feat = torch.load(f\"{self.audio_dir}/{row['filename']}.pt\")\n",
    "        text_feat = torch.load(f\"{self.text_dir}/{row['filename']}.pt\")\n",
    "        label = torch.tensor(row['label'], dtype=torch.float)\n",
    "        return audio_feat, text_feat, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_precomputed = PrecomputedFusionDataset(train_data, embedding_dir='cached_embeddings', task='train')\n",
    "val_ds_precomputed    = PrecomputedFusionDataset(val_data, embedding_dir='cached_embeddings', task='train')\n",
    "\n",
    "train_loader = DataLoader(train_ds_precomputed , batch_size=8, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds_precomputed , batch_size=8, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_feat = torch.load(\"cached_embeddings/train/audio/audio_1008.wav.pt\")\n",
    "# audio_feat = torch.load(\"cached_embeddings/train/text/audio_1008.wav.pt\")\n",
    "# audio_feat.shape,audio_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, optimizer, loss_fn, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for audio_feat, text_feat, target in dataloader:\n",
    "        audio_feat, text_feat, target = audio_feat.to(device), text_feat.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(audio_feat, text_feat).squeeze(1)  # (batch,)\n",
    "        loss = loss_fn(output, target)\n",
    "\n",
    "        loss.backward()\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch} | Train Loss: {avg_loss:.4f}\")\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "def validate_one_epoch(model, dataloader, loss_fn):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for audio_feat, text_feat, target in dataloader:\n",
    "            audio_feat, text_feat, target = audio_feat.to(device), text_feat.to(device), target.to(device)\n",
    "            output = model(audio_feat, text_feat).squeeze(1)\n",
    "\n",
    "            loss = loss_fn(output, target)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"Validation Loss: {avg_loss:.4f}\")\n",
    "    return avg_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model, optimizer, loss\n",
    "model = AudioTextFusionModel().to(DEVICE)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "patience = 0\n",
    "patience_limit = 15\n",
    "best_val_loss = float('inf')\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer, loss_fn, epoch)\n",
    "    val_loss = validate_one_epoch(model, val_loader, loss_fn)\n",
    "\n",
    "    if (val_loss<best_val_loss):\n",
    "        best_val_loss = val_loss\n",
    "        patience = 0\n",
    "        torch.save(model.state_dict(), f\"best_model_WaveLM_Bert_MLP.pt\")\n",
    "            # print(f\"Saved Best Model with RMSE: {best_rmse:.4f}\")\n",
    "    else:\n",
    "        patience = patience + 1\n",
    "        if(patience > patience_limit):\n",
    "            print(\"Early Stopping\")\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = AudioTextDataset(test_transcript_data, bert_tokenizer, task = 'test')\n",
    "test_loader = DataLoader(test_ds, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_loader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for audio_feat, text_feat, _ in tqdm(test_loader):\n",
    "            audio_feat, text_feat = audio_feat.to(device), text_feat.to(device)\n",
    "            preds = model(audio_feat, text_feat).squeeze(1)\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syedd\\AppData\\Local\\Temp\\ipykernel_75124\\3836587015.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_model_new.pt\"))\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [08:13<00:00, 19.74s/it]\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"best_model_WaveLM_Bert_MLP.pt\"))\n",
    "pred = predict(model,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>audio_706.wav</td>\n",
       "      <td>2.527446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>audio_800.wav</td>\n",
       "      <td>2.128209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>audio_68.wav</td>\n",
       "      <td>4.461556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>audio_1267.wav</td>\n",
       "      <td>2.586688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>audio_683.wav</td>\n",
       "      <td>2.601349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         filename     label\n",
       "0   audio_706.wav  2.527446\n",
       "1   audio_800.wav  2.128209\n",
       "2    audio_68.wav  4.461556\n",
       "3  audio_1267.wav  2.586688\n",
       "4   audio_683.wav  2.601349"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"dataset_shl/dataset/test.csv\")\n",
    "sub_df = pd.DataFrame()\n",
    "sub_df['filename'] = df_test['filename']\n",
    "sub_df['label'] = pred\n",
    "sub_df.to_csv(\"sub10.csv\" ,index = False)\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weighted Merges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>audio_706.wav</td>\n",
       "      <td>4.486119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>audio_800.wav</td>\n",
       "      <td>2.264364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>audio_68.wav</td>\n",
       "      <td>3.921659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>audio_1267.wav</td>\n",
       "      <td>2.468159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>audio_683.wav</td>\n",
       "      <td>2.256742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         filename     label\n",
       "0   audio_706.wav  4.486119\n",
       "1   audio_800.wav  2.264364\n",
       "2    audio_68.wav  3.921659\n",
       "3  audio_1267.wav  2.468159\n",
       "4   audio_683.wav  2.256742"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub3 = pd.read_csv(\"sub3.csv\")\n",
    "sub_3_plus_10 = weighted_merge(sub_df,sub3, 0.5)\n",
    "sub_3_plus_10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_3_plus_10.to_csv(\"sub3(1)_plus_10.csv\" ,index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11694977,
     "sourceId": 97919,
     "sourceType": "competition"
    },
    {
     "datasetId": 7055528,
     "sourceId": 11284641,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7055669,
     "sourceId": 11284850,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7057801,
     "sourceId": 11287870,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7057874,
     "sourceId": 11287981,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7058111,
     "sourceId": 11288282,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python (hmenv3)",
   "language": "python",
   "name": "hmenv3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
